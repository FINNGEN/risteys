= Pipeline

....
 ┌────┐
 │ qc │
 └────┘

 ┌──────────────────────┐        ┌────────────────────┐        ┌────────────────────────┐
 │ densify_first_events │        │ correlations: init │        │ medication_stats_logit │
 └┬─────────────────────┘        └┬───────────────────┘        └────────────────────────┘
  │  ┌─────────────┐              │  ┌───────────────────────┐
  ├─>│ basic_stats │              └─>│ correlations: compute │
  │  └─────────────┘                 └┬──────────────────────┘
  │  ┌──────────────────────┐         │  ┌───────────────────┐
  ├─>│ cumulative_incidence │         └─>│ correlations: csv │
  │  └──────────────────────┘            └┬──────────────────┘
  │  ┌────────────────┐                   │
  ├─>│ surv_mortality │                   │
  │  └────────────────┘                   │
  │                                       │
  │                                       │  ┌────────────────────────────┐
  │                                       └─>│ surv_select_endpoint_pairs │
  │                                          └┬───────────────────────────┘
  │                                           │  ┌───────────────┐
  │                                           └─>│ surv_analysis │
  └─────────────────────────────────────────────>└───────────────┘
....


== Requirements

- https://docs.conda.io/en/latest/miniconda.html[conda]
- an internet connection (use https://conda.github.io/conda-pack/[conda-pack] for deploying to an environment lacking internet)


== Setup

1. Create a conda environment, e.g. 'mypipeline', with `conda create -n mypipeline`

2. Activate it with `conda activate mypipeline`

3. Install dependencies with `conda install -c conda-forge -c bioconda --file conda-pkgs.txt`


== Scripts and data dependencies

Follow the tables below to understand the pipeline steps and their dependencies.

_Legend:_ +
⚫ = _uses as input_ +
🔷 = _creates as output_

=== Basic stats

// Tables are best viewed rendered, for example on GitHub.

[%header,cols=6*]
|===
| script (in order)
| <<file-minpheno,minimum phenotypes>>
| <<file-wide-fevents,wide first-events>>
| densified first-events
| <<file-filter-indivs,filter of individuals>>
| basic stats

| link:qc.py[qc.py]
| ⚫
| ⚫
| –
| –
| –

| [[file-dense-fevents]]link:densify_first_events.py[densify_first_events.py]
| –
| ⚫
| 🔷
| –
| –

| link:basic_stats.py[basic_stats.py]
| ⚫
| –
| ⚫
| ⚫
| 🔷
|===


=== Cumulative incidence

[%header,cols=5*]
|===
| script
| <<file-endp-defs,endpoint definitions>>
| <<file-dense-fevents,densified first-events>>
| <<file-infocols,endpoint info columns>>
| cumulative incidences

| link:cumulative_incidence.py[cumulative_incidence.py]
| ⚫
| ⚫
| ⚫
| 🔷
|===


=== Correlations

[%header,cols=5*]
|===
| script (in order)
| <<file-wide-fevents,wide first-events>>
| phenotypes matrix
| metrics
| correlations

| @link:https://github.com/FINNGEN/endpcorr/blob/main/main.py[FINNGEN/endpcorr/main.py] init
| ⚫
| 🔷
| –
| –

| @link:https://github.com/FINNGEN/endpcorr/blob/main/main.py[FINNGEN/endpcorr/main.py] compute
| –
| ⚫
| 🔷
| –

| [[file-correlations]]@link:https://github.com/FINNGEN/endpcorr/blob/main/main.py[FINNGEN/endpcorr/main.py] csv
| –
| –
| ⚫
| 🔷
|===


=== Mortality

[%header,cols=6*]
|===
| script
| <<file-endp-defs,endpoint definitions>>
| <<file-dense-fevents,densified first-events>>
| <<file-minpheno,minimum phenotypes>>
| mortality stats
| mortality timings log

| link:surv_mortality.py[surv_mortality.py]
| ⚫
| ⚫
| ⚫
| 🔷
| 🔷
|===


=== Drug statistics

[%header,cols=7*]
|===
| script
| <<file-wide-fevents,wide first-events>>
| <<file-detailed-longit,detailed longitudinal events>>
| <<file-endp-defs,endpoint definitions>>
| <<file-minpheno,minimum phenotypes>>
| drug stats
| drug counts

| link:medication_stats_logit.py[medication_stats_logit.py]
| ⚫
| ⚫
| ⚫
| ⚫
| 🔷
| 🔷
|===


=== Survival analyses

Survival analyses can be run directly with python scripts. However if you are going to run a lot of them you might want to checkout the link:cromwell/surv.wdl[WDL pipeline] for easier use.

[%header,cols=9*]
|===
| script (in order)
| <<file-endp-defs,endpoint definitions>>
| <<file-priority-list,endpoint priority list>>
| <<file-correlations,endpoint correlations>>
| selected endpoint pairs
| <<file-dense-fevents,densified first-events>>
| <<file-minpheno,minimum phenotypes>>
| survival analyses stats
| survival analyses timings

| link:surv_select_endpoint_pairs.py[surv_select_endpoint_pairs.py]
| ⚫
| ⚫
| ⚫
| 🔷
| –
| –
| –
| –

| link:surv_analysis.py[surv_analysis.py]
| ⚫
| –
| –
| ⚫
| ⚫
| ⚫
| 🔷
| 🔷
|===


== Input data files

The `?` in file names below denotes a placeholder for versioning information.

* [[file-minpheno]]mininum phenotypes
** name: `+finngen_R?_minimum_?.txt.gz+`
** FinnGen source: e-Science team
** note: This file needs to be formatted to CSV for processing in Risteys pipeline.

* [[file-wide-fevents]]wide first-events
** name: `+finngen_R?_endpoint_?.txt.gz+`
** FinnGen source: e-Science team
** note: This file needs to be formatted to CSV for processing in Risteys pipeline.

* [[file-filter-indivs]]filter of individuals
** name: `+R?_COV_PHENO_V?.txt.gz+`
** FinnGen source: analysis team, e-Science team
** note: This file needs to be formatted to CSV for processing in Risteys pipeline.

* [[file-endp-defs]]endpoint definitions
** name: `+Endpoints_Controls_FINNGEN_ENDPOINTS_DF?_Final_?_corrected.xlsx+`
** FinnGen source: clinical team
** note: This file needs to be formatted to CSV for processing in Risteys pipeline.

* [[file-infocols]]endpoint info columns
** note: This file is just the columns `FINNGENID`, `FU_END_AGE` and `SEX` extracted from the <<file-wide-fevents,wide first-events>> file

* [[file-detailed-longit]]detailed longitudinal events
** name: `+finngen_R?_detailed_longitudinal_?.txt.gz+`
** FinnGen source: e-Science team
** note: This file needs to be formatted to CSV for processing in Risteys pipeline.

* [[file-priority-list]]endpoint priority list
** name: FinnGen priority phenotypes (sheet: priority) (Google Sheet)
** FinnGen source: clinical team
** note: Extract the `Code` column to a file.
